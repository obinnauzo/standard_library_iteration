{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5dd3bdca",
   "metadata": {},
   "source": [
    "# Python Standard Library Project - Boston Advisory \n",
    "\n",
    "### By: Okonkwo Obinna Uzochukwu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce6ce4",
   "metadata": {},
   "source": [
    "### Project Python Standard Library (***Iteration***)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f4c268",
   "metadata": {},
   "source": [
    "For this project you have 4 files containing information about persons.\n",
    "\n",
    "The files are:\n",
    "\n",
    "    personal_info.csv - personal information such as name, gender, etc. (one row per person)\n",
    "    vehicles.csv - what vehicle people own (one row per person)\n",
    "    employment.csv - where a person is employed (one row per person)\n",
    "    update_status.csv - when the person's data was created and last updated\n",
    "\n",
    "Each file contains a key, SSN, which uniquely identifies a person.\n",
    "\n",
    "This key is present in all four files.\n",
    "\n",
    "You are guaranteed that the same SSN value is present in every file, and that it only appears once per file.\n",
    "\n",
    "In addition, the files are all sorted by SSN, i.e. the SSN values appear in the same order in each file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02cd875",
   "metadata": {},
   "source": [
    "##### Goal 1\n",
    "\n",
    "Your first task is to create iterators for each of the four files that contained cleaned up data, of the correct type (e.g. string, int, date, etc), and represented by a named tuple.\n",
    "\n",
    "For now these four iterators are just separate, independent iterators."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab79846e",
   "metadata": {},
   "source": [
    "##### Goal 2\n",
    "\n",
    "Create a single iterable that combines all the columns from all the iterators.\n",
    "\n",
    "The iterable should yield named tuples containing all the columns.\n",
    "Make sure that the SSN's across the files match!\n",
    "\n",
    "All the files are guaranteed to be in SSN sort order, and every SSN is unique, and every SSN appears in every file.\n",
    "\n",
    "Make sure the SSN is not repeated 4 times - one time per row is enough!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22ed2a8",
   "metadata": {},
   "source": [
    "##### Goal 3\n",
    "\n",
    "Next, you want to identify any stale records, where stale simply means the record has not been updated since 3/1/2017 (e.g. last update date < 3/1/2017). Create an iterator that only contains current records (i.e. not stale) based on the `last_updated` field from the `status_update` file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127dffae",
   "metadata": {},
   "source": [
    "##### Goal 4\n",
    "\n",
    "Find the largest group of car makes for each gender.\n",
    "\n",
    "Possibly more than one such group per gender exists (equal sizes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4da252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from itertools import chain, compress, groupby, tee\n",
    "\n",
    "#### constants.py\n",
    "\n",
    "\n",
    "#### Files\n",
    "\n",
    "fname_employment = 'employment.csv'\n",
    "\n",
    "fname_update_status = 'update_status.csv'\n",
    "\n",
    "fname_vehicles = 'vehicles.csv'\n",
    "\n",
    "fname_personal_info = 'personal_info.csv'\n",
    "\n",
    "\n",
    "fnames = fname_employment, fname_update_status, fname_vehicles, fname_personal_info\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Parsers\n",
    "\n",
    "def parse_date(value, *, fmt='%Y-%m-%dT%H:%M:%SZ'):\n",
    "    return datetime.strptime(value, fmt)\n",
    "\n",
    "employment_parser = (str, str, str, str)\n",
    "\n",
    "update_status_parser = (str, parse_date, parse_date)\n",
    "\n",
    "vehicles_parser = (str, str, str, int)\n",
    "\n",
    "personal_info_parser = (str, str, str, str, str)\n",
    "\n",
    "\n",
    "parsers = employment_parser, update_status_parser, vehicles_parser, personal_info_parser\n",
    "                \n",
    "\n",
    "\n",
    "    \n",
    "#### Named Tuple Names\n",
    "\n",
    "employment_class_name = 'Employment'\n",
    "\n",
    "update_status_class_name = 'UpdateStatus'\n",
    "\n",
    "vehicles_class_name = 'Vehicles'\n",
    "\n",
    "personal_class_name = 'Personal'\n",
    "\n",
    "\n",
    "class_names = employment_class_name, update_status_class_name, vehicles_class_name, personal_class_name\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Field Inclusion and Exclusion\n",
    "\n",
    "employment_field_compress = [True, True, True, False]\n",
    "\n",
    "update_status_fileld_compress = [False, True, True]\n",
    "\n",
    "vehicle_field_compress = [False, True, True, True]\n",
    "\n",
    "personal_field_compress = [True, True, True, True, True]\n",
    "\n",
    "\n",
    "compress_fields = (employment_field_compress, update_status_fileld_compress, \n",
    "                   vehicle_field_compress, personal_field_compress\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9904153",
   "metadata": {},
   "outputs": [],
   "source": [
    "########## parse_utils.py\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import namedtuple\n",
    "\n",
    "def csv_parser(fname, *, delimiter=',', quotechar='\"', include_reader=False):\n",
    "    with open(fname) as f:\n",
    "        reader = csv.reader(f, delimiter=delimiter, quotechar=quotechar)\n",
    "        if not include_reader:\n",
    "            next(f)\n",
    "        yield from reader\n",
    "\n",
    "\n",
    "def parse_date(value, *, fmt='%Y-%m-%dT%H:%M:%SZ'):\n",
    "    return datetime.strptime(value, fmt)\n",
    "\n",
    "\n",
    "def extract_field_names(fname):\n",
    "    reader = csv_parser(fname, include_reader=True)\n",
    "    return next(reader)\n",
    "\n",
    "\n",
    "def create_namedtuple_class(fname, class_name):\n",
    "    fields = extract_field_names(fname)\n",
    "    return namedtuple(class_name, fields)\n",
    "\n",
    "def create_combo_named_tuple_class(fnames, compress_fields):\n",
    "    compress_fields = chain.from_iterable(compress_fields)\n",
    "    \n",
    "    field_names = chain.from_iterable(extract_field_names(fname) for fname in fnames)\n",
    "    compressed_fields_names = compress(field_names, compress_fields)\n",
    "    return namedtuple('Data', compressed_fields_names)\n",
    "\n",
    "def iter_file(fname, class_name, parser):\n",
    "    nt_class = create_namedtuple_class(fname, class_name)\n",
    "    reader = csv_parser(fname)\n",
    "    for row in reader:\n",
    "        parsed_data = (parse_fn(value) for value, parse_fn in zip(row, parser))\n",
    "        yield nt_class(*parsed_data)\n",
    "        \n",
    "        \n",
    "def iter_combined_plain_tuple(fnames, class_names, parsers, compress_fields):\n",
    "    \n",
    "    compress_fields = list(chain.from_iterable(compress_fields))\n",
    "    \n",
    "    zipped_tuples = zip(*[iter_file(fname, class_name, parser)\n",
    "               for fname, class_name, parser in zip(fnames, class_names, parsers)])\n",
    "    \n",
    "    merged_iter = (chain.from_iterable(zipped_tuple) for zipped_tuple in zipped_tuples)\n",
    "    \n",
    "    for row in merged_iter:\n",
    "        compressed_row = compress(row, compress_fields)\n",
    "        yield tuple(compressed_row)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "def iter_combined(fnames, class_names, parsers, compress_fields):\n",
    "    combo_nt = create_combo_named_tuple_class(fnames, compress_fields)\n",
    "    compress_fields = list(chain.from_iterable(compress_fields))\n",
    "    \n",
    "    zipped_tuples = zip(*[iter_file(fname, class_name, parser)\n",
    "               for fname, class_name, parser in zip(fnames, class_names, parsers)])\n",
    "    \n",
    "    merged_iter = (chain.from_iterable(zipped_tuple) for zipped_tuple in zipped_tuples)\n",
    "    \n",
    "    for row in merged_iter:\n",
    "        compressed_row = compress(row, compress_fields)\n",
    "        yield combo_nt(*compressed_row)\n",
    "\n",
    "        \n",
    "def filtered_iter_combined(fnames, class_names, parsers, compress_fields, *, key=None):\n",
    "    iter_combo = iter_combined(fnames, class_names, parsers, compress_fields)\n",
    "    \n",
    "    yield from filter(key, iter_combo)\n",
    "    \n",
    "    \n",
    "def group_data(fnames, class_names, parsers, compress_fields, filter_key, group_key, gender):\n",
    "    data = filtered_iter_combined(fnames, class_names, parsers, compress_fields, key=filter_key)\n",
    "    data_filtered = (row for row in data if row.gender == gender)\n",
    "    sorted_data = sorted(data_filtered, key=group_key)\n",
    "    groups = groupby(sorted_data, key=group_key)\n",
    "    group_counts = ((g[0], len(list(g[1]))) for g in groups)\n",
    "    return group_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7597c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = filtered_iter_combined(fnames, class_names, parsers, compress_fields,\n",
    "                                    key=lambda x: x.last_updated >= datetime(2017, 3, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dec0bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12d16fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_key(item):\n",
    "    return item.vehicle_make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3490de29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_data = sorted(data, key=group_key)\n",
    "# groups_1 = groupby(sorted_data, key=group_key)\n",
    "\n",
    "# groups_2 = groupby(sorted_data, key=group_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405c3a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rg_1 = next(groups_1)\n",
    "# rg_2 = next(groups_2)\n",
    "\n",
    "# print(id(groups_1), rg_1, id(rg_1), rg_1[0], id(rg_1[0]), rg_1[1], id(rg_1[1]))\n",
    "# print(id(groups_2), rg_2, id(rg_2), rg_2[0], id(rg_2[0]), rg_2[1], id(rg_2[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a6931de",
   "metadata": {},
   "outputs": [],
   "source": [
    "###[(k, len(list(v))) for k, v in (groups)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "618d62ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_f = (item for item in groups_1 if item[0][0] == 'Female')\n",
    "# data_f = ((item[0][1], len(list(item[1]))) for item in group_f)\n",
    "\n",
    "# print('group_f')\n",
    "# for row in data_f:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aaac9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# group_m = (item for item in groups_2 if item[0][0] == 'Male')\n",
    "# data_m = ((item[0][1], len(list(item[1]))) for item in group_m)\n",
    "\n",
    "# print('group_m')\n",
    "# for row in data_m:\n",
    "#     print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347ab979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cbe0fcbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1, data_2 = tee(data, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1fef02ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groups_m\n",
      "('Acura', 7)\n",
      "('Aptera', 1)\n",
      "('Aston Martin', 3)\n",
      "('Audi', 14)\n",
      "('Austin', 1)\n",
      "('BMW', 12)\n",
      "('Bentley', 3)\n",
      "('Buick', 13)\n",
      "('Cadillac', 9)\n",
      "('Chevrolet', 30)\n",
      "('Chrysler', 3)\n",
      "('Corbin', 1)\n",
      "('Daewoo', 1)\n",
      "('Dodge', 22)\n",
      "('Eagle', 1)\n",
      "('Ford', 40)\n",
      "('GMC', 28)\n",
      "('Geo', 2)\n",
      "('Honda', 9)\n",
      "('Hyundai', 8)\n",
      "('Infiniti', 7)\n",
      "('Isuzu', 3)\n",
      "('Jaguar', 4)\n",
      "('Jeep', 7)\n",
      "('Jensen', 1)\n",
      "('Kia', 5)\n",
      "('Lamborghini', 4)\n",
      "('Land Rover', 3)\n",
      "('Lexus', 6)\n",
      "('Lincoln', 5)\n",
      "('Lotus', 5)\n",
      "('Maserati', 3)\n",
      "('Maybach', 2)\n",
      "('Mazda', 13)\n",
      "('Mercedes-Benz', 19)\n",
      "('Mercury', 11)\n",
      "('Mitsubishi', 28)\n",
      "('Nissan', 6)\n",
      "('Oldsmobile', 5)\n",
      "('Panoz', 2)\n",
      "('Plymouth', 4)\n",
      "('Pontiac', 11)\n",
      "('Porsche', 4)\n",
      "('Rolls-Royce', 1)\n",
      "('Saab', 8)\n",
      "('Saturn', 3)\n",
      "('Scion', 1)\n",
      "('Smart', 1)\n",
      "('Subaru', 8)\n",
      "('Suzuki', 2)\n",
      "('Toyota', 21)\n",
      "('Volkswagen', 16)\n",
      "('Volvo', 10)\n",
      "\n",
      "\n",
      "groups_f\n",
      "('Acura', 9)\n",
      "('Aston Martin', 2)\n",
      "('Audi', 13)\n",
      "('Austin', 1)\n",
      "('BMW', 12)\n",
      "('Bentley', 4)\n",
      "('Bugatti', 1)\n",
      "('Buick', 11)\n",
      "('Cadillac', 6)\n",
      "('Chevrolet', 42)\n",
      "('Chrysler', 6)\n",
      "('Dodge', 17)\n",
      "('Eagle', 1)\n",
      "('Ford', 42)\n",
      "('GMC', 22)\n",
      "('Geo', 1)\n",
      "('Honda', 8)\n",
      "('Hyundai', 4)\n",
      "('Infiniti', 9)\n",
      "('Isuzu', 3)\n",
      "('Jaguar', 3)\n",
      "('Jeep', 5)\n",
      "('Kia', 9)\n",
      "('Lamborghini', 2)\n",
      "('Land Rover', 8)\n",
      "('Lexus', 15)\n",
      "('Lincoln', 4)\n",
      "('Lotus', 5)\n",
      "('Mazda', 13)\n",
      "('Mercedes-Benz', 17)\n",
      "('Mercury', 5)\n",
      "('Mitsubishi', 22)\n",
      "('Morgan', 1)\n",
      "('Nissan', 12)\n",
      "('Oldsmobile', 8)\n",
      "('Panoz', 1)\n",
      "('Plymouth', 3)\n",
      "('Pontiac', 14)\n",
      "('Porsche', 3)\n",
      "('Rolls-Royce', 1)\n",
      "('Saab', 3)\n",
      "('Saturn', 3)\n",
      "('Scion', 2)\n",
      "('Subaru', 6)\n",
      "('Suzuki', 12)\n",
      "('Toyota', 20)\n",
      "('Volkswagen', 10)\n",
      "('Volvo', 13)\n"
     ]
    }
   ],
   "source": [
    "data_m = (row for row in data_1 if row.gender == 'Male')\n",
    "\n",
    "sorted_data_m = sorted(data_m, key=group_key)\n",
    "groups_m = groupby(sorted_data_m, key=group_key)\n",
    "groups_m_count = ((g[0], len(list(g[1]))) for g in groups_m)\n",
    "                   \n",
    "print('groups_m')\n",
    "for row in groups_m_count:\n",
    "    print(row)\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "data_f = (row for row in data_2 if row.gender == 'Female')\n",
    "\n",
    "sorted_data_f = sorted(data_f, key=group_key)\n",
    "groups_f = groupby(sorted_data_f, key=group_key)\n",
    "groups_f_count = ((g[0], len(list(g[1]))) for g in groups_f)\n",
    "\n",
    "print('groups_f')\n",
    "for row in groups_f_count:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a437293",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_date = datetime(2017, 3, 1)\n",
    "result_m = group_data(fnames, class_names, parsers, compress_fields,\n",
    "           filter_key=lambda row: row.last_updated >= cutoff_date,\n",
    "          group_key=lambda row: row.vehicle_make,\n",
    "          gender='Male')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2300b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Acura', 7)\n",
      "('Aptera', 1)\n",
      "('Aston Martin', 3)\n",
      "('Audi', 14)\n",
      "('Austin', 1)\n",
      "('BMW', 12)\n",
      "('Bentley', 3)\n",
      "('Buick', 13)\n",
      "('Cadillac', 9)\n",
      "('Chevrolet', 30)\n",
      "('Chrysler', 3)\n",
      "('Corbin', 1)\n",
      "('Daewoo', 1)\n",
      "('Dodge', 22)\n",
      "('Eagle', 1)\n",
      "('Ford', 40)\n",
      "('GMC', 28)\n",
      "('Geo', 2)\n",
      "('Honda', 9)\n",
      "('Hyundai', 8)\n",
      "('Infiniti', 7)\n",
      "('Isuzu', 3)\n",
      "('Jaguar', 4)\n",
      "('Jeep', 7)\n",
      "('Jensen', 1)\n",
      "('Kia', 5)\n",
      "('Lamborghini', 4)\n",
      "('Land Rover', 3)\n",
      "('Lexus', 6)\n",
      "('Lincoln', 5)\n",
      "('Lotus', 5)\n",
      "('Maserati', 3)\n",
      "('Maybach', 2)\n",
      "('Mazda', 13)\n",
      "('Mercedes-Benz', 19)\n",
      "('Mercury', 11)\n",
      "('Mitsubishi', 28)\n",
      "('Nissan', 6)\n",
      "('Oldsmobile', 5)\n",
      "('Panoz', 2)\n",
      "('Plymouth', 4)\n",
      "('Pontiac', 11)\n",
      "('Porsche', 4)\n",
      "('Rolls-Royce', 1)\n",
      "('Saab', 8)\n",
      "('Saturn', 3)\n",
      "('Scion', 1)\n",
      "('Smart', 1)\n",
      "('Subaru', 8)\n",
      "('Suzuki', 2)\n",
      "('Toyota', 21)\n",
      "('Volkswagen', 16)\n",
      "('Volvo', 10)\n"
     ]
    }
   ],
   "source": [
    "for row in result_m:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44c8dc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = iter_combined(fnames, class_names, parsers, compress_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a00dcaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(employer='Stiedemann-Bailey', department='Research and Development', employee_id='29-0890771', last_updated=datetime.datetime(2017, 10, 7, 0, 14, 42), created=datetime.datetime(2016, 1, 24, 21, 19, 30), vehicle_make='Oldsmobile', vehicle_model='Bravada', model_year=1993, ssn='100-53-9824', first_name='Sebastiano', last_name='Tester', gender='Male', language='Icelandic')\n",
      "Data(employer='Nicolas and Sons', department='Sales', employee_id='41-6841359', last_updated=datetime.datetime(2017, 1, 23, 11, 23, 17), created=datetime.datetime(2016, 1, 27, 4, 32, 57), vehicle_make='Ford', vehicle_model='Mustang', model_year=1997, ssn='101-71-4702', first_name='Cayla', last_name='MacDonagh', gender='Female', language='Lao')\n",
      "Data(employer='Connelly Group', department='Research and Development', employee_id='98-7952860', last_updated=datetime.datetime(2017, 10, 4, 11, 21, 30), created=datetime.datetime(2016, 9, 21, 23, 4, 7), vehicle_make='GMC', vehicle_model='Yukon', model_year=2005, ssn='101-84-0356', first_name='Nomi', last_name='Lipprose', gender='Female', language='Yiddish')\n",
      "Data(employer='Upton LLC', department='Marketing', employee_id='56-9817552', last_updated=datetime.datetime(2017, 3, 28, 12, 38, 29), created=datetime.datetime(2016, 4, 15, 11, 37, 17), vehicle_make='Oldsmobile', vehicle_model='Intrigue', model_year=2000, ssn='104-22-0928', first_name='Justinian', last_name='Kunzelmann', gender='Male', language='Dhivehi')\n",
      "Data(employer='Zemlak-Olson', department='Business Development', employee_id='46-2886707', last_updated=datetime.datetime(2018, 2, 19, 1, 34, 33), created=datetime.datetime(2016, 3, 15, 14, 7, 57), vehicle_make='Ford', vehicle_model='Crown Victoria', model_year=2008, ssn='104-84-7144', first_name='Claudianus', last_name='Brixey', gender='Male', language='Afrikaans')\n",
      "Data(employer='Kohler, Bradtke and Davis', department='Support', employee_id='80-0975518', last_updated=datetime.datetime(2017, 7, 24, 8, 58, 52), created=datetime.datetime(2016, 7, 23, 17, 58, 35), vehicle_make='Ford', vehicle_model='Mustang', model_year=2001, ssn='105-27-5541', first_name='Federico', last_name='Aggett', gender='Male', language='Chinese')\n",
      "Data(employer='Roberts, Torphy and Dach', department='Human Resources', employee_id='77-4895332', last_updated=datetime.datetime(2018, 2, 14, 11, 32, 39), created=datetime.datetime(2016, 12, 15, 5, 46, 43), vehicle_make='Chrysler', vehicle_model='300', model_year=2008, ssn='105-85-7486', first_name='Angelina', last_name='McAvey', gender='Female', language='Punjabi')\n",
      "Data(employer='Lind-Jast', department='Marketing', employee_id='79-6418731', last_updated=datetime.datetime(2018, 3, 24, 14, 29, 33), created=datetime.datetime(2016, 3, 24, 3, 43, 3), vehicle_make='Isuzu', vehicle_model='Hombre Space', model_year=2000, ssn='105-91-5022', first_name='Moselle', last_name='Apfel', gender='Female', language='Latvian')\n",
      "Data(employer='Bashirian-Lueilwitz', department='Engineering', employee_id='44-3328799', last_updated=datetime.datetime(2017, 5, 11, 1, 48, 32), created=datetime.datetime(2016, 5, 31, 0, 38, 13), vehicle_make='Chevrolet', vehicle_model='Silverado 3500', model_year=2004, ssn='105-91-7777', first_name='Audi', last_name='Roach', gender='Female', language='Estonian')\n",
      "Data(employer='Windler, Marks and Haley', department='Services', employee_id='54-6271885', last_updated=datetime.datetime(2017, 10, 21, 1, 7, 28), created=datetime.datetime(2016, 9, 8, 4, 2, 12), vehicle_make='GMC', vehicle_model='Sonoma Club', model_year=1992, ssn='106-35-1938', first_name='Mackenzie', last_name='Nussey', gender='Male', language='Swedish')\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(next(gen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8cf88b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
